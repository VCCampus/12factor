{
  "promptEngineering": {
    "coreConceptsTitle": "Core Concepts",
    "title": "Prompt Engineering Mastery",
    "description": "Learn practical prompt engineering techniques through interactive lessons and hands-on exercises",
    "startLearning": "Start Learning",
    "viewLessons": "View Lessons",
    "lessonsLabel": "Lessons",
    "interactiveLearning": "Interactive Learning",
    "learningPath": "Learning Path",
    "learningPathDescription": "Master prompt engineering through structured lessons and practical exercises",
    "backToLessons": "Back to Lessons",
    "lesson": "Lesson",
    "chapter": "Chapter",
    "theory": "Theory",
    "examples": "Examples",
    "exercises": "exercises",
    "practicalExamples": "Practical Examples",
    "prerequisites": "Prerequisites",
    "exercise": "Exercise",
    "instructions": "Instructions",
    "hints": "Hints",
    "showHints": "Show Hints",
    "hideHints": "Hide Hints",
    "yourPrompt": "Your Prompt",
    "enterPromptHere": "Enter your prompt here...",
    "checkAnswer": "Check Answer",
    "reset": "Reset",
    "exerciseCompleted": "Exercise completed!",
    "exerciseCorrect": "Great! Your prompt works correctly.",
    "exerciseIncorrect": "Not quite right. Try refining your prompt.",
    "validationError": "Error validating your prompt.",
    "tryAgainWithHints": "Try again or check the hints for guidance.",
    "previousLesson": "Previous Lesson",
    "nextLesson": "Next Lesson",
    "practiceExercise": "Practice Exercise",
    "stage1": {
      "name": "Fundamentals",
      "description": "Master the basics of clear and effective prompt communication"
    },
    "stage2": {
      "name": "Intermediate",
      "description": "Learn structured prompting and output formatting techniques"
    },
    "stage3": {
      "name": "Advanced",
      "description": "Explore complex prompting strategies and reasoning techniques"
    },
    "stage4": {
      "name": "Practical",
      "description": "Apply prompt engineering in real-world scenarios and workflows"
    },
    "lesson1": {
      "title": "Basic Prompt Structure",
      "summary": "Learn the fundamental elements of effective prompt design and clear communication with AI systems."
    },
    "lesson2": {
      "title": "Being Clear and Direct",
      "summary": "Eliminate ambiguity and get precise responses by being specific about your requirements."
    },
    "lesson3": {
      "title": "Role Prompting",
      "summary": "Assign specific roles and perspectives to improve response quality and consistency."
    },
    "lesson4": {
      "title": "Data/Instruction Separation",
      "summary": "Use clear delimiters to separate data from instructions for better prompt clarity."
    },
    "lesson5": {
      "title": "Output Formatting",
      "summary": "Specify exact output formats to get structured, consistent responses."
    },
    "lesson6": {
      "title": "Step-by-Step Thinking",
      "summary": "Leverage chain-of-thought prompting for better reasoning and problem-solving."
    },
    "course": {
      "fundamentals": {
        "title": "Fundamentals Course",
        "summary": "Learn fundamental concepts and core principles of prompt engineering"
      },
      "intermediate": {
        "title": "Intermediate Course",
        "summary": "Master advanced techniques for data separation, output formatting, and systematic thinking"
      }
    },
    "nextCourse": "Next Course",
    "integratedCourse": "Integrated Course",
    "courseOverview": "Course Overview",
    "sections": "sections",
    "previousCourse": "Previous Course",
    "clickToStartPractice": "Click the editor below to start practice",
    "learningMode": "Learning Mode",
    "playgroundMode": "Playground",
    "practiceMode": "Practice Mode",
    "learningContent": "Learning Content",
    "experimentalPlayground": "Experimental Playground",
    "interactiveExercise": "Interactive Exercise",
    "experimentWithThisPrompt": "Experiment with this prompt",
    "promptExamples": "Prompt Examples",
    "practicalExercises": "Practical Exercises",
    "previous": "Previous",
    "next": "Next",
    "learningTips": "Learning Tips",
    "tryDifferentVariations": "Try Different Prompt Variations",
    "editPrompt": "Edit Prompt",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Set AI's role and behavior rules...",
    "userPrompt": "User Prompt",
    "userPromptPlaceholder": "Enter your question or instruction...",
    "runPrompt": "Run Prompt",
    "running": "Running...",
    "aiResponse": "AI Response",
    "goodPromptQuality": "Good output quality",
    "canImprove": "Output can improve",
    "aiThinking": "AI is thinking...",
    "clickRunPrompt": "Click \"Run Prompt\" to see AI response",
    "coreConceptsTitle": "Core Concepts",
    "keyTechniquesTitle": "Key Techniques",
    "commonPitfallsTitle": "Common Pitfalls",
    "promptTemplate": "Prompt Template",
    "promptTemplatePlaceholder": "Enter your prompt template with variables like {{example1}}, {{example2}}...",
    "templateHint": "Use {{format}} for placeholders that will be replaced",
    "templateVariables": "Template Variables",
    "enterValue": "Enter value...",
    "finalPrompt": "Final Prompt (Generated)",
    "finalPromptHint": "This is the final prompt after variable replacement",
    "rateLimitError": "Rate limit exceeded. Please wait a moment and try again.",
    "serviceUnavailableError": "Service temporarily unavailable. Please try again later.",
    "generalError": "An error occurred. Please try again.",
    "evaluationError": "Could not evaluate prompt quality automatically."
  },
  "courses": {
    "fundamentals": {
      "title": "Fundamentals Course",
      "summary": "Comprehensive step-by-step guide to mastering Claude's best prompt engineering practices. Learn three core skills: API structure, clear communication, and role assignment.",
      "sections": {
        "basicStructure": {
          "title": "Chapter 1: Basic Prompt Structure",
          "theory": "Learn the required parameters of the Messages API: model, max_tokens, messages array. Master the user/assistant conversation format and correct usage of system prompts.",
          "examples": [
            "Correct format: role='user', content='Hi Claude, how are you?'",
            "Wrong format: Missing role and content fields",
            "System prompt: You are a logical reasoning expert who specializes in solving complex logical problems"
          ],
          "coreConcepts": {
            "0": "**Message Alternation Rule** - User and Assistant messages MUST alternate, and messages MUST start with a User turn",
            "1": "**System Prompts** - System prompts provide context, instructions, and guidelines to AI models, structurally separate from user & assistant messages",
            "2": "**Message Formatting** - When using message APIs, insert newlines between each message, or AI will consider unseparated content as a single message",
            "3": "**Multi-turn Conversations** - You can include multiple User/Assistant pairs in a prompt, and have AI continue from an ending Assistant message",
            "4": "**Value of System Prompts** - Well-written system prompts improve AI performance, such as increasing AI's ability to follow rules and instructions"
          },
          "keyTechniques": {
            "0": "Messages API parameters: model, max_tokens, messages",
            "1": "User/Assistant conversation format",
            "2": "System prompt configuration",
            "3": "Message alternation rules"
          },
          "commonPitfalls": {
            "0": "Not alternating user/assistant messages",
            "1": "Starting with assistant message instead of user",
            "2": "Mixing system prompt with conversation messages"
          },
          "exercises": {
            "countToThree": {
              "instructions": "Use the correct user/assistant format to have Claude count to three",
              "template": "[Replace this text]",
              "hints": [
                "State your request directly",
                "Use simple clear instructions",
                "Avoid unnecessary complexity"
              ]
            },
            "systemPromptChild": {
              "instructions": "Modify the SYSTEM_PROMPT to make Claude respond like a 3-year-old child",
              "template": "SYSTEM_PROMPT = '[Replace this text]'",
              "hints": [
                "Think about how 3-year-olds speak",
                "Use simple vocabulary and expressions",
                "Add childlike language features"
              ]
            }
          }
        },
        "clearCommunication": {
          "title": "Chapter 2: Being Clear and Direct",
          "theory": "Claude needs clear instructions. Follow the golden rule: if you show your prompt to a colleague and they're confused, Claude will be confused too.",
          "examples": [
            "Vague: Write a haiku about robots",
            "Clear: Write a haiku about robots, skip the preamble and go straight to the poem",
            "Vague: Who is the best basketball player of all time?",
            "Force choice: Who is the best basketball player of all time? While there are different opinions, if you had to choose one, who would it be?"
          ],
          "coreConcepts": {
            "0": "**Clarity Principle** - Vague instructions lead to poor results, specific requirements get good output. State your needs and expectations directly",
            "1": "**Format Constraints** - Specify output format, length, style and other constraints to make AI produce results that meet expectations",
            "2": "**Colleague Test** - Show your prompt to a colleague, if they're confused, AI will be confused too",
            "3": "**Forced Choice** - Use 'if you had to choose one' to make AI avoid vague hedging and give clear answers"
          },
          "keyTechniques": {
            "0": "Direct and specific instructions",
            "1": "Format constraints and requirements",
            "2": "Forcing specific choices when needed",
            "3": "The colleague test for clarity"
          },
          "commonPitfalls": {
            "0": "Being too vague or ambiguous",
            "1": "Not specifying output format",
            "2": "Allowing AI to avoid making choices"
          },
          "exercises": {
            "spanishResponse": {
              "instructions": "Modify the SYSTEM_PROMPT to make Claude respond in Spanish",
              "template": "SYSTEM_PROMPT = '[Replace this text]'",
              "hints": [
                "Tell Claude directly which language to use",
                "You can specify language requirements in the system prompt"
              ]
            },
            "onePlayerOnly": {
              "instructions": "Have Claude respond with only one player's name, no other text or punctuation",
              "template": "[Replace this text]",
              "hints": [
                "Be very specific about format requirements",
                "Clearly state no explanations or other content",
                "Force Claude to make a choice"
              ]
            },
            "longStory": {
              "instructions": "Write a story of 800+ words",
              "template": "[Replace this text]",
              "hints": [
                "Clearly specify story length",
                "You can provide specific story themes",
                "Request detailed descriptions and plot development"
              ]
            }
          }
        },
        "rolePrompting": {
          "title": "Chapter 3: Assigning Roles (Role Prompting)",
          "theory": "Assigning specific roles to Claude can significantly improve performance. Role setting can change response style, tone, and level of expertise.",
          "examples": [
            "No role: What about skateboarding?",
            "Cat role: system='You are a cat' will answer from a cat's perspective",
            "Logic error: Jack looks at Anne, Anne looks at George, Jack is married George is unmarried, is a married person looking at an unmarried person?",
            "Logic expert: system='You are a logical reasoning expert' correctly analyzes this problem"
          ],
          "coreConcepts": {
            "0": "**Role Context** - Claude only knows what you tell it, so provide complete role background and context",
            "1": "**Role Effects** - Role setting can change response style, tone, and expertise level, improving performance in specific domains",
            "2": "**Setting Location** - Roles can be set in system prompts or user messages, both methods are effective",
            "3": "**Detail Importance** - The more detailed the role description, the better the effect. Include specific professional background and behavioral expectations"
          },
          "keyTechniques": {
            "0": "Assigning specific roles and personas",
            "1": "Providing detailed role context",
            "2": "Using roles to improve domain expertise",
            "3": "Setting roles in system prompts"
          },
          "commonPitfalls": {
            "0": "Using roles without sufficient context",
            "1": "Not being specific about role expertise",
            "2": "Forgetting to set appropriate tone with role"
          },
          "exercises": {
            "mathCorrection": {
              "instructions": "Have Claude find the math error: 2x-3=9, 2x=6, x=3",
              "template": "Is this equation solved correctly?\n\n2x - 3 = 9\n2x = 6\nx = 3",
              "hints": [
                "Assign Claude a math teacher or logic expert role",
                "Request careful checking of each step",
                "Emphasize finding the error"
              ]
            }
          }
        }
      }
    },
    "intermediate": {
      "title": "Intermediate Prompt Engineering",
      "summary": "Master advanced techniques for data separation, output formatting, and systematic thinking",
      "sections": {
        "dataInstructions": {
          "title": "Chapter 4: Separating Data from Instructions",
          "theory": "Learn how to create reusable prompt templates by cleanly separating instructions from variable data. This chapter covers the use of XML tags, f-string templating, and best practices for handling user input safely and effectively.",
          "examples": [
            "Create dynamic prompts with variable substitution using f-strings",
            "Use XML tags to clearly separate data from instructions",
            "Handle messy or unclear input by providing proper boundaries"
          ],
          "keyTechniques": {
            "0": "F-string templating with variables",
            "1": "XML tag wrapping for data boundaries",
            "2": "Clear instruction-data separation",
            "3": "Input validation patterns"
          },
          "commonPitfalls": {
            "0": "Not clearly separating instructions from data",
            "1": "Forgetting to wrap variable content in XML tags",
            "2": "Using unclear variable names in templates"
          }
        },
        "formatting": {
          "title": "Chapter 5: Formatting Output & Speaking for Claude",
          "theory": "Master techniques for controlling and formatting AI output. Learn how to use XML tags, JSON formatting, and prefilling to get exactly the response format you need.",
          "examples": [
            "Format output in XML tags for easy parsing",
            "Use prefilling to guide response generation",
            "Enforce JSON output for structured data"
          ],
          "keyTechniques": {
            "0": "XML tag output formatting",
            "1": "Assistant turn prefilling",
            "2": "JSON output enforcement",
            "3": "Multi-variable template formatting"
          },
          "commonPitfalls": {
            "0": "Not using consistent output format tags",
            "1": "Forgetting to prefill the opening tag",
            "2": "Not enforcing format requirements"
          }
        },
        "thinking": {
          "title": "Chapter 6: Precognition (Thinking Step by Step)",
          "theory": "Improve AI accuracy by implementing chain-of-thought prompting. Learn how to structure reasoning processes and use step-by-step thinking for complex problems.",
          "examples": [
            "Guide AI through explicit reasoning steps",
            "Use XML-tagged thinking sections for organization",
            "Apply multi-perspective analysis for better decisions"
          ],
          "keyTechniques": {
            "0": "Explicit reasoning steps",
            "1": "XML-tagged thinking sections",
            "2": "Multi-perspective analysis",
            "3": "Brainstorming before answering"
          },
          "commonPitfalls": {
            "0": "Asking for thinking without showing the work",
            "1": "Not structuring the thinking process",
            "2": "Skipping reasoning for complex problems"
          }
        },
        "examples": {
          "title": "Chapter 7: Using Examples (Few-Shot Prompting)",
          "theory": "Leverage the power of examples to guide AI behavior. Learn how to select effective examples, format them properly, and use few-shot prompting for consistent results.",
          "examples": [
            "Choose optimal examples for guidance",
            "Format examples for maximum impact",
            "Apply examples across different domains"
          ],
          "keyTechniques": {
            "0": "Few-shot example selection",
            "1": "Example formatting patterns",
            "2": "Context-appropriate examples",
            "3": "Output format consistency"
          },
          "commonPitfalls": {
            "0": "Using poor quality or irrelevant examples",
            "1": "Not maintaining consistent format across examples",
            "2": "Too few or too many examples"
          }
        }
      }
    }
  },
  "practiceExercises": {
    "fundamentals": {
      "chapter1BasicStructure": {
        "title": "Chapter 1 Exercise: Count to Three (API Structure)",
        "description": "Learn the correct Messages API format. This is the most basic exercise to ensure you understand how to construct effective prompts.",
        "expectedOutput": "A response containing 1, 2, 3 with clear formatting.",
        "hints": {
          "0": "State your requirement directly: 'Count to three'",
          "1": "Use simple, clear instructions",
          "2": "Avoid unnecessary complexity"
        },
        "variations": {
          "directInstruction": {
            "name": "Direct Instruction",
            "explanation": "The simplest, most direct approach"
          },
          "clearFormat": {
            "name": "Clear Format",
            "explanation": "Specifies the output format"
          }
        }
      },
      "chapter1SystemPrompt": {
        "title": "Chapter 1 Exercise: 3-Year-Old Role (System Prompt)",
        "description": "Experience the power of system prompts. Through role assignment, completely change Claude's response style.",
        "expectedOutput": "An excited response like a 3-year-old child, possibly with laughter, simple vocabulary, and innocent expressions.",
        "hints": {
          "0": "Think about how a 3-year-old talks: excited, curious, simple vocabulary",
          "1": "You can add childish expressions like 'soo big' or 'giggles'",
          "2": "The system prompt defines the AI's entire 'personality'"
        },
        "variations": {
          "noSystemPrompt": {
            "name": "No System Prompt",
            "explanation": "No system prompt set, see the default response"
          },
          "strictScientist": {
            "name": "Strict Scientist",
            "explanation": "System: 'You are a strict physicist. Give precise scientific answers.'"
          },
          "friendlyTeacher": {
            "name": "Friendly Teacher",
            "explanation": "System: 'You are a friendly teacher explaining to children.'"
          }
        }
      },
      "chapter2Spanish": {
        "title": "Chapter 2 Exercise: Spanish Response (Clear Instructions)",
        "description": "Learn how to give clear instructions to control output language. This exercise shows that the API can precisely follow your requirements.",
        "expectedOutput": "A response in Spanish, including Spanish greetings like 'Hola'.",
        "hints": {
          "0": "Directly state the language requirement in the prompt",
          "1": "You can say 'Please respond in Spanish' or 'Responde en español'",
          "2": "Observe how AI completely switches languages"
        },
        "variations": {
          "frenchResponse": {
            "name": "French Response",
            "explanation": "Request response in French"
          },
          "bilingualResponse": {
            "name": "Bilingual Response",
            "explanation": "Request response in both English and Spanish"
          }
        }
      },
      "chapter2Basketball": {
        "title": "Chapter 2 Exercise: Just One Name (Precise Format)",
        "description": "Learn how to give extremely specific format requirements. This exercise teaches you how to get precisely controlled output.",
        "expectedOutput": "Just one player's name, no other text or explanation.",
        "hints": {
          "0": "Be very specific about format requirements",
          "1": "Clearly state no explanations or other content",
          "2": "Force AI to make a choice"
        },
        "variations": {
          "withExplanation": {
            "name": "With Explanation",
            "explanation": "Allow Claude to explain the choice"
          },
          "top3List": {
            "name": "Top 3 List",
            "explanation": "Request top 3 players instead of one"
          },
          "specificFormat": {
            "name": "Specific Format",
            "explanation": "Request name with one reason"
          }
        }
      },
      "chapter2LongStory": {
        "title": "Chapter 2 Exercise: Write Long Story (Clear Requirements)",
        "description": "Learn how to control output length through clear requirements. This exercise demonstrates the importance of providing specific metrics.",
        "expectedOutput": "A story of at least 800 words about a robot learning to paint, with rich plot and detailed descriptions.",
        "hints": {
          "0": "Clearly request story length: at least 800 words",
          "1": "Provide specific story topic and theme",
          "2": "Request detailed descriptions and plot development",
          "3": "Can request inclusion of dialogue and scene descriptions"
        },
        "variations": {
          "noLength": {
            "name": "No Length Requirement",
            "explanation": "Don't specify length, see default story length"
          },
          "exactWordCount": {
            "name": "Exact Word Count",
            "explanation": "Specify exact word count and request specific elements"
          },
          "longerStory": {
            "name": "Longer Story",
            "explanation": "Request longer length and more complex structure"
          }
        }
      },
      "chapter3MathLogic": {
        "title": "Chapter 3 Exercise: Math Error Check (Role Assignment)",
        "description": "Experience how role assignment affects logical reasoning. By assigning Claude an expert role, improve its performance in specific domains.",
        "expectedOutput": "Find the math error: The step from 2x-3=9 to 2x=6 is wrong, it should be 2x=12.",
        "hints": {
          "0": "Assign Claude a math teacher or logic expert role",
          "1": "Request careful checking of each calculation step",
          "2": "Emphasize finding where the error is"
        },
        "variations": {
          "noRole": {
            "name": "No Role Set",
            "explanation": "No specific role set, see basic performance"
          },
          "logicExpert": {
            "name": "Logic Expert",
            "explanation": "Set as logic reasoning expert, focus on logical analysis"
          },
          "studentRole": {
            "name": "Student Role",
            "explanation": "Set as a student learning math, show thinking process"
          }
        }
      }
    },
    "intermediate": {
      "chapter4Haiku": {
        "title": "Chapter 4 Practice: Haiku Template Exercise",
        "description": "Create a reusable prompt template for generating haikus about any topic",
        "expectedOutput": "A haiku that mentions the specified topic",
        "hints": {
          "0": "Use {{TOPIC}} as a placeholder in your prompt template",
          "1": "Make sure to ask for a haiku format",
          "2": "Test with different topics to verify the template works"
        },
        "variations": {
          "simple": {
            "name": "Simple Prompt",
            "explanation": "Direct approach without template variables"
          },
          "template": {
            "name": "Template Approach",
            "explanation": "Using variable substitution for reusability"
          }
        }
      },
      "chapter4DogXML": {
        "title": "Chapter 4 Practice: XML Tag Separation",
        "description": "Fix a messy prompt by using XML tags to separate the question from surrounding text",
        "expectedOutput": "A clear answer about dogs being brown",
        "hints": {
          "0": "Wrap the actual question in XML tags",
          "1": "This helps AI focus on what's important",
          "2": "Compare the results with and without XML tags"
        },
        "variations": {
          "noXML": {
            "name": "Without XML Tags",
            "explanation": "See how messy text confuses the AI"
          },
          "clearFormat": {
            "name": "Clean Format",
            "explanation": "Well-structured prompt with clear boundaries"
          }
        }
      },
      "chapter5Curry": {
        "title": "Chapter 5 Practice: Response Prefilling",
        "description": "Use prefilling to guide Claude toward a specific basketball player",
        "expectedOutput": "An argument for Stephen Curry as the best player",
        "hints": {
          "0": "Start Claude's response with partial text about Curry",
          "1": "This technique 'speaks for Claude' to guide direction",
          "2": "The prefill should feel natural to continue"
        },
        "variations": {
          "noPrefill": {
            "name": "No Prefilling",
            "explanation": "Standard response without guidance"
          },
          "curryPrefill": {
            "name": "Curry Prefill",
            "explanation": "Guide response toward Stephen Curry"
          }
        }
      },
      "chapter5TwoHaikus": {
        "title": "Chapter 5 Practice: Multiple Output Formatting",
        "description": "Format output to contain two separate haikus with clear boundaries",
        "expectedOutput": "Two distinct haikus about cats, each in its own tags",
        "hints": {
          "0": "Ask for two haikus explicitly",
          "1": "Use XML tags to separate each haiku",
          "2": "Make sure the format is consistent"
        },
        "variations": {
          "oneHaiku": {
            "name": "Single Haiku",
            "explanation": "Standard single haiku request"
          },
          "numbered": {
            "name": "Numbered Format",
            "explanation": "Use numbered tags for organization"
          }
        }
      },
      "chapter6EmailClass": {
        "title": "Chapter 6 Practice: Step-by-Step Email Classification",
        "description": "Classify emails by having AI think through the process step by step",
        "expectedOutput": "Classification with visible reasoning process",
        "hints": {
          "0": "Ask AI to show its thinking process",
          "1": "Use XML tags to organize the reasoning",
          "2": "Think through each category systematically"
        },
        "variations": {
          "noThinking": {
            "name": "Direct Classification",
            "explanation": "Immediate classification without reasoning"
          },
          "detailedThinking": {
            "name": "Detailed Analysis",
            "explanation": "Comprehensive step-by-step analysis"
          }
        }
      },
      "chapter6EmailFormatted": {
        "title": "Chapter 6 Practice: Formatted Classification Output",
        "description": "Get classification results in a specific XML format",
        "expectedOutput": "Classification letter wrapped in answer tags",
        "hints": {
          "0": "Specify exact output format with XML tags",
          "1": "Ask for just the letter, nothing else",
          "2": "Use prefilling if needed to enforce format"
        },
        "variations": {
          "withExplanation": {
            "name": "With Explanation",
            "explanation": "Include reasoning with classification"
          },
          "xmlOnly": {
            "name": "XML Format Only",
            "explanation": "Strict format requirements"
          }
        }
      },
      "chapter7EmailExamples": {
        "title": "Chapter 7 Practice: Few-Shot Email Classification",
        "description": "Use examples to teach AI how to classify emails consistently",
        "expectedOutput": "Correct classification following example patterns",
        "hints": {
          "0": "Provide 2-3 clear examples of classifications",
          "1": "Show the exact format you want",
          "2": "Include examples for different categories"
        },
        "variations": {
          "noExamples": {
            "name": "No Examples",
            "explanation": "Classification without guidance examples"
          },
          "moreExamples": {
            "name": "Extended Examples",
            "explanation": "Multiple examples for better guidance"
          }
        }
      }
    }
  },
  "playground": {
    "fundamentals": {
      "basicStructure": {
        "title": "Chapter 1 Playground: Basic Structure & System Prompts",
        "creativeCounting": {
          "name": "Creative Counting",
          "description": "Experiment with different ways to count - try making it fun!",
          "variations": {
            "basic": "Basic Creative",
            "basicExplanation": "Simple creative counting approach",
            "storytelling": "Story Format",
            "storytellingExplanation": "Count by embedding numbers in a narrative",
            "poetic": "Poetic Style",
            "poeticExplanation": "Use rhymes and poetic language for counting",
            "withContext": "Educational Context",
            "withContextExplanation": "Add educational context with system prompt"
          }
        },
        "systemPromptExperiment": {
          "name": "System Prompt Structure",
          "description": "Learn how system prompts guide AI behavior and response style",
          "variations": {
            "basic": "No System Prompt",
            "basicExplanation": "Standard AI response without system guidance",
            "structured": "Structured Request",
            "structuredExplanation": "System prompt requesting clear structure",
            "detailed": "Detailed Instructions",
            "detailedExplanation": "System prompt asking for detailed scientific explanation",
            "simple": "Simplicity Request",
            "simpleExplanation": "System prompt requesting simple language"
          }
        },
        "hint1": "Try different creative approaches to basic tasks",
        "hint2": "Experiment with various system prompt structures",
        "hint3": "Notice how system prompts change AI response style"
      },
      "clearCommunication": {
        "title": "Chapter 2 Playground: Clear Communication",
        "languageExperiment": {
          "name": "Language Choice",
          "description": "Explore how AI chooses languages and explains decisions",
          "variations": {
            "basic": "Open Choice",
            "basicExplanation": "AI chooses any language and explains why",
            "specific": "Specific Language",
            "specificExplanation": "Request a specific language with cultural context",
            "comparative": "Language Comparison",
            "comparativeExplanation": "Compare greetings across multiple languages",
            "contextual": "Business Context",
            "contextualExplanation": "Professional greeting with business context"
          }
        },
        "formatExperiment": {
          "name": "Format Styles",
          "description": "Try different formatting approaches for lists and structure",
          "variations": {
            "basic": "Flexible Format",
            "basicExplanation": "AI chooses formatting style freely",
            "numbered": "Numbered List",
            "numberedExplanation": "Specific numbered list with explanations",
            "detailed": "Detailed Descriptions",
            "detailedExplanation": "Rich descriptions with reasons",
            "creative": "Creative Format",
            "creativeExplanation": "Creative presentation like poem or story"
          }
        },
        "hint1": "Be specific about your requirements",
        "hint2": "Try different output formats",
        "hint3": "Experiment with explicit vs implicit instructions"
      },
      "rolePrompting": {
        "title": "Chapter 3 Playground: Role Prompting",
        "roleComparison": {
          "name": "Role Comparison",
          "description": "Compare responses from different professional perspectives",
          "variations": {
            "basic": "No Role Context",
            "basicExplanation": "General AI response without specific professional role",
            "conservative": "Conservative Advisor",
            "conservativeExplanation": "Risk-averse financial advisor perspective",
            "aggressive": "Tech-Savvy Advisor",
            "aggressiveExplanation": "Digital asset specialist with growth focus",
            "balanced": "Certified Planner",
            "balancedExplanation": "Objective analysis from certified financial planner"
          }
        },
        "expertiseExperiment": {
          "name": "Expertise Levels",
          "description": "See how different expertise levels affect explanations",
          "variations": {
            "basic": "General Response",
            "basicExplanation": "Standard AI explanation without expertise role",
            "professor": "Academic Professor",
            "professorExplanation": "Data science professor making topics accessible",
            "beginner": "Beginner Tutor",
            "beginnerExplanation": "Tutor specialized in teaching absolute beginners",
            "practical": "Industry Expert",
            "practicalExplanation": "Working data scientist showing real applications"
          }
        },
        "hint1": "Try contrasting professional roles",
        "hint2": "Experiment with different expertise levels",
        "hint3": "Notice how role context shapes responses"
      }
    },
    "intermediate": {
      "dataInstructionSeparation": {
        "title": "Chapter 4 Playground: Data & Instruction Separation",
        "examples": {
          "animalSounds": {
            "name": "Animal Sound Generator",
            "description": "Create a template for generating animal sounds",
            "variations": {
              "withXML": {
                "name": "With XML Tags",
                "explanation": "Clear separation using XML boundaries"
              },
              "template": {
                "name": "Template Variables",
                "explanation": "Using variable substitution patterns"
              }
            }
          },
          "emailRewrite": {
            "name": "Email Rewriting Template",
            "description": "Template for rewriting emails in different styles",
            "variations": {
              "noXML": {
                "name": "Without XML",
                "explanation": "See how unclear boundaries affect results"
              },
              "formal": {
                "name": "Formal Style",
                "explanation": "Professional email rewriting template"
              }
            }
          }
        },
        "hints": {
          "0": "Use XML tags to clearly separate data from instructions",
          "1": "Create reusable templates with variable placeholders",
          "2": "Test templates with different inputs to verify consistency"
        }
      },
      "outputFormatting": {
        "title": "Chapter 5 Playground: Output Formatting Control",
        "examples": {
          "haikuXML": {
            "name": "XML-Formatted Haikus",
            "description": "Control haiku output format with XML tags",
            "variations": {
              "prefilled": {
                "name": "Prefilled Opening",
                "explanation": "Use prefilling to start the XML tag"
              },
              "json": {
                "name": "JSON Format",
                "explanation": "Structure haiku as JSON object"
              }
            }
          },
          "emailStyle": {
            "name": "Styled Email Output",
            "description": "Format email rewrites with dynamic XML tags",
            "variations": {
              "formal": {
                "name": "Formal Style",
                "explanation": "Professional email formatting"
              },
              "casual": {
                "name": "Casual Style",
                "explanation": "Informal email formatting"
              }
            }
          }
        },
        "hints": {
          "0": "Use XML tags to structure output clearly",
          "1": "Combine prefilling with format specifications",
          "2": "Experiment with different output structures"
        }
      },
      "stepByStepThinking": {
        "title": "Chapter 6 Playground: Chain-of-Thought Reasoning",
        "examples": {
          "movieReview": {
            "name": "Movie Review Analysis",
            "description": "Analyze sentiment with step-by-step reasoning",
            "variations": {
              "noThinking": {
                "name": "Direct Analysis",
                "explanation": "Immediate sentiment judgment"
              },
              "brainstorm": {
                "name": "Brainstorming Process",
                "explanation": "Show detailed thinking process"
              }
            }
          },
          "factChecking": {
            "name": "Fact Verification",
            "description": "Verify facts through systematic reasoning",
            "variations": {
              "direct": {
                "name": "Direct Answer",
                "explanation": "Immediate response without research"
              },
              "detailed": {
                "name": "Research Process",
                "explanation": "Show research and verification steps"
              }
            }
          }
        },
        "hints": {
          "0": "Ask AI to show its reasoning process explicitly",
          "1": "Use XML tags to organize thinking steps",
          "2": "Compare results with and without step-by-step analysis"
        }
      },
      "fewShotExamples": {
        "title": "Chapter 7 Playground: Example-Driven Prompting",
        "examples": {
          "parentBot": {
            "name": "Parent Response Bot",
            "description": "Use examples to create consistent parenting responses",
            "variations": {
              "noExample": {
                "name": "Role-Based Only",
                "explanation": "Using system prompt without examples"
              },
              "multipleExamples": {
                "name": "Multiple Examples",
                "explanation": "Several examples for better consistency"
              }
            }
          },
          "dataExtraction": {
            "name": "Structured Data Extraction",
            "description": "Extract information using example formatting",
            "variations": {
              "noFormat": {
                "name": "Unstructured Output",
                "explanation": "Free-form data extraction"
              },
              "jsonFormat": {
                "name": "JSON Structure",
                "explanation": "Structured JSON output format"
              }
            }
          }
        },
        "hints": {
          "0": "Choose examples that represent the desired output clearly",
          "1": "Use 2-3 examples for best results",
          "2": "Maintain consistent formatting across all examples"
        }
      }
    }
  },
  "rateLimitError": "Rate limit exceeded. Please wait a moment and try again.",
  "serviceUnavailableError": "Service temporarily unavailable. Please try again later.",
  "generalError": "An error occurred while processing your request. Please try again.",
  "evaluationError": "Failed to evaluate prompt quality. Please try again."
}